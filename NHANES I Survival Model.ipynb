{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d043572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import shap\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import interpret.glassbox\n",
    "import xgboost\n",
    "import matplotlib.pylab as pl\n",
    "import shap\n",
    "import xgboost\n",
    "%matplotlib inline \n",
    "matplotlib.use('tkagg')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as pl\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import Counter\n",
    "import time\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import pandas_profiling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt.pyll.base import scope\n",
    "import pyspark\n",
    "data = pd.read_csv('cohort.csv')\n",
    "# data = pd.read_csv('cohortpetit.csv')\n",
    "# data2 = pd.read_csv('cohort100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48970fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "# Hyperparameters tuning\n",
    "\n",
    "from hyperopt import STATUS_OK, fmin, hp, tpe, SparkTrials\n",
    "\n",
    "# Some constants\n",
    "\n",
    "SEED = 1234\n",
    "VALID_SIZE = 0.2\n",
    "TARGET = 'outcome'\n",
    "\n",
    "def c_statistic_harrell(pred, labels):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if int(labels[j]) > 0 and abs(int(labels[i])) > int(labels[j]):\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total\n",
    "\n",
    "#-----------------------XGBoost--------------------------#\n",
    "\n",
    "def score_xgb(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    \n",
    "    n_folds = 5\n",
    "    val_scores = []\n",
    "    skf = KFold(n_splits = n_folds, shuffle = False)\n",
    "    num_boost_round=2000\n",
    "    #k-fold CV\n",
    "    for train_index, val_index in skf.split(X_train): \n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        dtrain = xgboost.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgboost.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "        gbm_model = xgboost.train(params, dtrain, num_boost_round,\n",
    "                              evals=watchlist,\n",
    "                              verbose_eval=500)\n",
    "        \n",
    "        predictions = gbm_model.predict(dval,\n",
    "                                    ntree_limit=gbm_model.best_iteration + 1)\n",
    "        val_scores.append(c_statistic_harrell(predictions, list(y_val)))\n",
    "    \n",
    "    score = np.mean(val_scores) #Objective: maximize mean 5-fold CV C-index \n",
    "    \n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize_xgb(score, \n",
    "             random_state=SEED):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space of \n",
    "    hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # XGB param ranges obtained from Barnwal A, Cho H, Hocking T (2020). Survival regression with accelerated failure time model in XGBoost: \n",
    "    # With some excpetions as I observed that the optimal range is less wider that what they suggest\n",
    "    space = {\n",
    "        'eta':                         hp.loguniform('eta', np.log(0.001), np.log(1)),\n",
    "        'max_depth':                   scope.int(hp.quniform('max_depth', 2,10,1)),\n",
    "        'min_child_weight':            hp.loguniform('min_child_weight', np.log(0.001), np.log(10)),\n",
    "        'reg_alpha':                   hp.loguniform('reg_alpha', np.log(0.001), np.log(10)),\n",
    "        'reg_lambda':                  hp.loguniform('reg_lambda', np.log(0.001), np.log(10)),\n",
    "        'subsample':                   hp.uniform('subsample', 0.75, 1),\n",
    "        \"objective\": \"survival:cox\",\n",
    "        \"predictor\": \"gpu_predictor\"\n",
    "    }\n",
    "    \n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                max_evals=100)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89eb70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['time']\n",
    "y_event = data['event']\n",
    "y = y.head(1000)\n",
    "y_event = y_event.head(1000)\n",
    "X = data.drop(['time'], axis = 1)\n",
    "X = X.drop(['event'], axis = 1)\n",
    "X=X.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c87f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b78ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = [i for i in data.columns if data[i].dtype in [np.int64, np.int64]]\n",
    "feature_names = [i for i in X.columns ]\n",
    "X = X[feature_names]\n",
    "X = X.head(1000)\n",
    "# my_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n",
    "# model_ebm = interpret.glassbox.ExplainableBoostingRegressor()\n",
    "# model_ebm.fit(X, y)\n",
    "##########\n",
    "# X100 = data2[feature_names]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc445d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Running XGBoost ----\")\n",
    "start=time.time()\n",
    "xgb_best_hyperparams = optimize_xgb(score_xgb)\n",
    "end=time.time()\n",
    "print(\"Done: took\", (end-start)/60, \"minutes\")\n",
    "print(\"---- Results for XGBoost ----\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(xgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bf144",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_hyperparams['max_depth']=round(xgb_best_hyperparams['max_depth'])\n",
    "xgb_best_hyperparams['objective']=\"survival:cox\"\n",
    "xgb_best_hyperparams['predictor']=\"gpu_predictor\"\n",
    "print(xgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae937d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-cox-nloglik:5.18859\ttrain-cox-nloglik:6.50720\n",
      "[500]\teval-cox-nloglik:5.18649\ttrain-cox-nloglik:6.48958\n",
      "[1000]\teval-cox-nloglik:5.19037\ttrain-cox-nloglik:6.48091\n",
      "[1500]\teval-cox-nloglik:5.19416\ttrain-cox-nloglik:6.47528\n",
      "[1999]\teval-cox-nloglik:5.19735\ttrain-cox-nloglik:6.47083\n",
      "XGB Done: 0.660853316723762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    }
   ],
   "source": [
    "num_boost_round=2000\n",
    "dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "dval = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "xgb_model = xgboost.train(xgb_best_hyperparams, dtrain, num_boost_round,\n",
    "                      evals=watchlist,\n",
    "                      verbose_eval=500)\n",
    "\n",
    "predictions = xgb_model.predict(dval,\n",
    "                            ntree_limit=xgb_model.best_iteration + 1)\n",
    "\n",
    "xgb_test_score = c_statistic_harrell(predictions, list(y_test))\n",
    "print(\"XGB Done:\", xgb_test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fd2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'eta': 0.0012482292166029548,\n",
    "    \"max_depth\": 3,\n",
    "    'min_child_weight': 2.1899878853989163,\n",
    "    'reg_alpha': 0.16737772985552463,\n",
    "    'reg_lambda': 0.21803902714013768,\n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\":  0.8874909590869486,\n",
    "    \"predictor\": \"gpu_predictor\"\n",
    "}\n",
    "# model = xgboost.train(params, xgb_full, 10000, evals = [(xgb_full, \"test\")], verbose_eval=1000)\n",
    "full_xy = X.copy()\n",
    "y_labels = y.copy()\n",
    "full_xy['y'] = y_labels\n",
    "X_features = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c875c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My list of binary columns are :\n",
      " ['men', 'smoker', 'p.dm', 'htn_med', 'c10']\n",
      "\n",
      "My list of cont. columns are :\n",
      " ['age', 'pas', 'ct', 'chdl', 'cldl', 'tg', 'charlson', 'ckd.epi', 'hematocrit']\n"
     ]
    }
   ],
   "source": [
    "full_xy = X.copy()\n",
    "y_labels = y.copy()\n",
    "full_xy['y'] = y_labels\n",
    "X_features = X.columns\n",
    "myHazRatios = [[] for i in range(len(X.columns))]\n",
    "myIndexes = [i for i in range(len(X.columns))]\n",
    "# print(myHazRatios_all, myIndexes_all)\n",
    "myBinCols = [col for col in X.columns if all(X[col].value_counts().index.isin([0, 1]))]\n",
    "myContCols = [col for col in X.columns if not all(X[col].value_counts().index.isin([0, 1]))]\n",
    "\n",
    "print(\"My list of binary columns are :\\n\", myBinCols)\n",
    "\n",
    "print(\"\\nMy list of cont. columns are :\\n\", myContCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b51be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 1001):\n",
    "#   sample with replacement:\n",
    "    X_train = full_xy.sample(n = full_xy.shape[0], random_state = i, replace = True) #sample w/ replacement num rows\n",
    "    y_train = X_train['y'] #y train are X_trains y column\n",
    "    X_train = X_train.drop(columns = ['y']) #X_train then needs to drop the y column\n",
    "    X_test = full_xy.drop(X_train.index) #test features are the full - X_train\n",
    "    y_test = X_test['y'] #y test are X_tests y column\n",
    "    X_test = X_test.drop(columns = ['y']) #X_test then needs to drop they column\n",
    "    xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "    xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "    print('iteration', i)\n",
    "    model_train = xgboost.train(params, xgb_train, 2000, evals = [(xgb_test, \"test\")], verbose_eval=False)\n",
    "    \n",
    "#   get the SHAP vals and a HR from these based on our model\n",
    "    shap_values_full = shap.TreeExplainer(model_train).shap_values(X)\n",
    "    \n",
    "#   build a list of HazRatios indexing by j columns\n",
    "    for j in range(len(myIndexes)):\n",
    "        curSHAP = shap_values_full[:, j]\n",
    "        curCol = X.columns[j]\n",
    "        # if continuous, split by mean\n",
    "        if (curCol in myContCols):\n",
    "            myMean = X[curCol].mean()\n",
    "            myHazRatios[j].append(np.mean(np.exp(curSHAP[X[curCol] >= myMean]))\n",
    "                                      /np.mean(np.exp(curSHAP[X[curCol] < myMean])))\n",
    "        # else, split by 1 or 0\n",
    "        else:\n",
    "            myHazRatios[j].append(np.mean(np.exp(curSHAP[X[curCol] == 1]))\n",
    "                                    /np.mean(np.exp(curSHAP[X[curCol] == 0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c0b459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1401471], [1.004879], [1.2034696], [1.0091059], [0.97980917], [1.0057719], [0.9798243], [0.9776175], [1.0245229], [0.9793414], [1.0311009], [0.9471054], [0.99844146], [1.0351961]]\n",
      "Index(['age', 'men', 'smoker', 'p.dm', 'pas', 'ct', 'chdl', 'cldl', 'tg',\n",
      "       'htn_med', 'charlson', 'ckd.epi', 'c10', 'hematocrit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# myHazRatios \n",
    "# indexed by column index\n",
    "X_features = X.columns\n",
    "mySummaries = []\n",
    "for i in range(len(myHazRatios)):\n",
    "    myHazRatios[i].sort()\n",
    "    mySummaries.append([np.mean(myHazRatios[i])])\n",
    "print(mySummaries)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36201e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "# create a train/test split\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "watchlist = [(xgb_train, 'train'), (xgb_test, 'test')]\n",
    "# model_train = xgboost.train(params, xgb_train, 20000, evals = [(xgb_test, \"test\")], verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df084bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.train(params, xgb_train, 20000, evals = watchlist, verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_statistic_harrell(pred, labels):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if int(labels[j]) > 0 and abs(int(labels[i])) > int(labels[j]):\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total\n",
    "\n",
    "# see how well we can order people by survival, 1 = perfect ordering\n",
    "c_statistic_harrell(model.predict(xgb_full, ntree_limit=15000), list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6832103",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(model).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('tkagg',force=True)\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.get_backend()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859dbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'eta': 0.001178734512359433,\n",
    "    \"max_depth\": 3,\n",
    "    'min_child_weight': 1.497139871118963,\n",
    "    'reg_alpha': 0.14836099959046609,\n",
    "    'reg_lambda': 0.729907543598251,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.8506093620966385,\n",
    "    \"predictor\": \"gpu_predictor\"\n",
    "}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_event, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_full = xgboost.DMatrix(X, label=y_event)\n",
    "\n",
    "# create a train/test split\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "watchlist = [(xgb_train, 'train'), (xgb_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = xgboost.train(params2, xgb_train, 20000, evals = watchlist, verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_statistic_harrell(model2.predict(xgb_full, ntree_limit=20000), list(y_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_event.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc675c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainerModel = shap.TreeExplainer(model2)\n",
    "shap_values_Model = explainerModel.shap_values(X)\n",
    "def shap_plot(j):\n",
    "    p = shap.force_plot(explainerModel.expected_value, shap_values_Model[j], X.iloc[[j]])\n",
    "    return(p)\n",
    "shap_plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83faf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['age']==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(4619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72838ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['charlson']>=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80faafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d69952",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(4300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6710dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pass \"age\" instead of an index because dependence_plot() will find it in X's column names for us\n",
    "# glucosa was automatically chosen for coloring based on a potential interaction to check that\n",
    "# the interaction is really in the model see SHAP interaction values below\n",
    "shap.dependence_plot(\"charlson\", shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12442ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"chdl\", shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eed92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"men\", shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6767281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a couple minutes since SHAP interaction values take a factor of 2 * # features\n",
    "# more time than SHAP values to compute\n",
    "shap_interaction_values = shap.TreeExplainer(model).shap_interaction_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfdb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_interaction_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d69094",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (\"age\", \"ckd.epi\"),\n",
    "    shap_interaction_values, X\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a095d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (\"age\", \"tg\"),\n",
    "    shap_interaction_values, X\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705238f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.abs(shap_interaction_values).sum(0)\n",
    "for i in range(tmp.shape[0]):\n",
    "    tmp[i,i] = 0\n",
    "inds = np.argsort(-tmp.sum(0))[:50]\n",
    "tmp2 = tmp[inds,:][:,inds]\n",
    "pl.figure(figsize=(12,12))\n",
    "pl.imshow(tmp2)\n",
    "pl.yticks(range(tmp2.shape[0]), X.columns[inds], rotation=50.4, horizontalalignment=\"right\")\n",
    "pl.xticks(range(tmp2.shape[0]), X.columns[inds], rotation=50.4, horizontalalignment=\"left\")\n",
    "pl.gca().xaxis.tick_top()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "shap_pca2 = PCA(n_components=2).fit_transform(shap_values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b98b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=np.sum(shap_values,axis=1), linewidth=0, alpha=0.5)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
